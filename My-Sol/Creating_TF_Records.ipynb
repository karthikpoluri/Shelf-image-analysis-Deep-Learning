{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current images path \n",
    "img_path = 'D:\\\\images\\\\part02\\\\ShelfImages\\\\'\n",
    "# cropped parts destination\n",
    "cropped_path = 'D:\\\\images\\\\part02\\\\ditected\\\\'\n",
    "# Step 1 results path\n",
    "data_path = 'C:\\\\Users\\\\P V S Karthik\\\\projects\\\\Cerium_Systems_projects\\\\My_Sol\\\\'\n",
    "# output destination\n",
    "# detector_data_path = 'C:\\\\Users\\\\P V S Karthik\\\\projects\\\\Cerium_Systems_projects\\\\My_Sol\\\\'\n",
    "detector_data_path = 'D:\\\\images\\\\part02\\\\ditected\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rects and photos dataframes\n",
    "photos = pd.read_pickle(f'{data_path}photos.pkl')\n",
    "products = pd.read_pickle(f'{data_path}products.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CROP_TRIALS = 6\n",
    "CROP_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns random value in [s, f]\n",
    "def rand_between(s, f):\n",
    "    if s == f:\n",
    "        return s\n",
    "    return np.random.randint(s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_products, eval_products = [], []\n",
    "for img_file, is_train in photos[['file', 'is_train']].values:\n",
    "    img = cv2.imread(f'{img_path}{img_file}')\n",
    "    img_h, img_w, img_c = img.shape\n",
    "    for n in range(N_CROP_TRIALS):\n",
    "        # randomly crop square\n",
    "        c_size = rand_between(300, max(img_h, img_w))\n",
    "        x0 = rand_between(0, max(0, img_w - c_size))\n",
    "        y0 = rand_between(0, max(0, img_h - c_size))\n",
    "        x1 = min(img_w, x0 + c_size)\n",
    "        y1 = min(img_h, y0 + c_size)\n",
    "        # products totally inside crop rectangle\n",
    "        crop_products = products[(products.file == img_file) & \n",
    "                                 (products.xmin > x0) & (products.xmax < x1) &\n",
    "                                 (products.ymin > y0) & (products.ymax < y1)]\n",
    "        # no products inside crop rectangle? cropping trial failed...\n",
    "        if len(crop_products) == 0:\n",
    "            continue\n",
    "        # name the crop\n",
    "        crop_img_file = f'{img_file[:-4]}{x0}_{y0}_{x1}_{y1}.JPG'\n",
    "        # crop and reshape to CROP_SIZExCROP_SIZE or smaller \n",
    "        # keeping aspect ratio\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        h, w, c = crop.shape\n",
    "        ratio = min(CROP_SIZE/h, CROP_SIZE/w)\n",
    "        crop = cv2.resize(crop, (0,0), fx=ratio, fy=ratio)\n",
    "        crop = crop[0:CROP_SIZE, 0:CROP_SIZE]\n",
    "        h, w, c = crop.shape\n",
    "        # add crop inner products to train_products or eval_products list\n",
    "        for xmin, ymin, xmax, ymax in \\\n",
    "                crop_products[['xmin', 'ymin', 'xmax', 'ymax']].values:\n",
    "            xmin -= x0\n",
    "            xmax -= x0\n",
    "            ymin -= y0\n",
    "            ymax -= y0\n",
    "\n",
    "            xmin, xmax, ymin, ymax = [int(np.round(e * ratio)) \n",
    "                                      for e in [xmin, xmax, ymin, ymax]]\n",
    "            product = {'filename': crop_img_file, 'class':'pack', \n",
    "                       'width':w, 'height':h,\n",
    "                       'xmin':xmin, 'ymin':ymin, 'xmax':xmax, 'ymax':ymax}\n",
    "            if is_train:\n",
    "                train_products.append(product)\n",
    "            else:\n",
    "                eval_products.append(product)\n",
    "        # save crop top eval or train folder\n",
    "        subpath = ['eval/', 'train/'][is_train]\n",
    "        cv2.imwrite(f'{cropped_path}{subpath}{crop_img_file}', crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_products).set_index('filename')\n",
    "eval_df = pd.DataFrame(eval_products).set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1_P01_N1_S2_10_401_1363_2186.JPG</th>\n",
       "      <td>pack</td>\n",
       "      <td>764</td>\n",
       "      <td>1000</td>\n",
       "      <td>565</td>\n",
       "      <td>645</td>\n",
       "      <td>706</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_P01_N1_S2_10_401_1363_2186.JPG</th>\n",
       "      <td>pack</td>\n",
       "      <td>764</td>\n",
       "      <td>1000</td>\n",
       "      <td>576</td>\n",
       "      <td>295</td>\n",
       "      <td>717</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_P01_N1_S2_10_401_1363_2186.JPG</th>\n",
       "      <td>pack</td>\n",
       "      <td>764</td>\n",
       "      <td>1000</td>\n",
       "      <td>13</td>\n",
       "      <td>264</td>\n",
       "      <td>150</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_P01_N1_S2_10_401_1363_2186.JPG</th>\n",
       "      <td>pack</td>\n",
       "      <td>764</td>\n",
       "      <td>1000</td>\n",
       "      <td>157</td>\n",
       "      <td>654</td>\n",
       "      <td>298</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_P01_N1_S2_10_401_1363_2186.JPG</th>\n",
       "      <td>pack</td>\n",
       "      <td>764</td>\n",
       "      <td>1000</td>\n",
       "      <td>164</td>\n",
       "      <td>264</td>\n",
       "      <td>305</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  class  width  height  xmin  ymin  xmax  ymax\n",
       "filename                                                                      \n",
       "C1_P01_N1_S2_10_401_1363_2186.JPG  pack    764    1000   565   645   706   855\n",
       "C1_P01_N1_S2_10_401_1363_2186.JPG  pack    764    1000   576   295   717   506\n",
       "C1_P01_N1_S2_10_401_1363_2186.JPG  pack    764    1000    13   264   150   483\n",
       "C1_P01_N1_S2_10_401_1363_2186.JPG  pack    764    1000   157   654   298   864\n",
       "C1_P01_N1_S2_10_401_1363_2186.JPG  pack    764    1000   164   264   305   475"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at this point we have two folders with images and\n",
    "# two dataframes with information about packs\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPythonImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'pack':\n",
    "        return 1\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) \n",
    "            for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_records(images_path, examples, dst_file):\n",
    "    writer = tf.compat.v1.python_io.TFRecordWriter(dst_file)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, images_path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_tf_records(f'{cropped_path}train/', train_df, f'{detector_data_path}train.record')\n",
    "convert_to_tf_records(f'{cropped_path}eval/', eval_df, f'{detector_data_path}eval.record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function eval(source, globals=None, locals=None, /)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
